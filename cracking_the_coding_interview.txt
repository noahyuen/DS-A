1. The Interview Process
    - Assessment based on:
        - Analytical skills
        - Coding skills
        - Technical skills/computer science fundamentals
        - Experience
        - Culture fit/communication skills
    - * practice whiteboarding algorithms
        - don't just write seudocode

2. Behind the Scenes
    - The Microsoft Interview
        - Microsoft wants smart people, geeks, people who are passionate about technology
    - The Amazon Interview:
        - emphasis on scalability, system design, object-oriented programming
    - The Google Interview:
        - emphasis on designing scalable systems, analytical (algorithm) skills
    - The Apple Interview
    - The Facebook Interview

3. Special Situations:
    - Product (and Program) Management
    - Startups

4. Before the Interview
    - re-writing resume

5. Behavioral Questions
    - Go through each of the projects or components of your resume and ensure that you can talk about them in detail. *use the grid
      in the book to guide your answers
      - make sure to have one to three projects that you can talk about in detail
        - talk about the technical components in depth and the role you played in the projects
    - Questions to ask the interviewer:
        - Genuine questions:
            - questions that you actually want to know the answers to
        - Insightful question:
            - questions that demonstrate your knowledge or understanding of technology
        - Passion questions:
            - demonstrate your passion for technology and show that you're interested in learning and will be a strong contributor to the company
    - Answering Behavioral Questions

6. Big O (38-59):
    - Big O time is the language and metric we use to describe the efficiency of algorithms
    - Understanding this will enable you to judge when your algorithm is getter faster or slower
    - *Master this concept
    A. Time Complexity
        - Big O, Big Theta, Big Omega
            - Big O: describes the upper bound on the time of an algorithm
            - Big Omega: describes the lower bound, fastest case of an algorithm
            - Big Theta: describes both O and Omega, gives a tight bound on runtime
        - Best Case, Worst Case, Expected Case
            ex: Quick Sort (list sorted around pivot value)
            - Best Case: If all elements are equal, then quick sort will, on average, just traverse through the array once. This is O(N) (depending on the implementation).
            - Worst Case: If we get unlucky and the pivot is repeatedly the largest element in the array, then our recursion doesn't divide the array in half
              and recurse on each half. It just shrink the array by one element. This will degenerate runtime to O(N**2).
            - Expected Case: We can expect a runtime of O(N log N).
            - *For most algorithms, the worst case and expected case are the same. 
    B. Space Complexity (memory or space required by an algorithm)
    C. Drop the Constants
    D. Drop the Non-Dominant Terms
    E. Multi-Part Algorithms: Add vs. Multiply
        - Sequential For-Loops: Add 
        - Nested Loops: Multiply
    F. Amortized Time
        - ex: What is the runtime of automatically growing an ArrayList once it has reached capacity?
            - The insertion will take O(N) to create a new array of size 2N and then copy N elements over
            - However, this doesn't happen very often and the vast majority of the time insertion will be in O(1) time
        - Amortized time allows use to describe that, yes, this worst case happens every once in a while, but once it happens, it won't happen again for 
          so long that the cost is "amortized"
        - So what is the amortized time of extending an ArrayList?
            - As we insert elements we double the capacity when the size of the array is a power of 2. So after X elements, we double the capacity
              at array size 1, 2, 4, 8, ..., X. That doubling takes, respectively, 1, 2, 4, 8, ..., X copies.
            - X insertions take O(2X) time. The amortized time for each insertion is O(1).
    G. Log N Runtimes
        - ex: Binary Search
        - The total runtime is a matter of how many steps (dividing N by 2 each time) we can take until N becomes 1
            - Where k in the number of steps: 2 ** k = Nested
        - * When you see a problem where the number of elements in the problem space gets halved each time, that will likely be O(log N) runtime
    H. Recursive Runtimes
        - ex: a recursive algorithm that calls itself twice
        - Picture all of the functions calls in a tree, the tree will have depth N. Each node has two children, therefore each level will have twice
          as many calls as the one above it.
        - *When you have a recursive function that makes multiple calls, the runtime will often (but not always) look like O(branches ** depth),
          where branches is the number of times each recursive call branches. For the example, this gives us (2 ** N). 
        - The space complexity of this algorithm will be O(N). Although we have O(2 ** N) nodes in the tree total, only O(N) exist at any given time. 
          Therefore, we only need to have O(N) memory available.
    I. Examples and Exercises
        1. Sequential For-Loops: O(N)
        2. Nested For-Loops: O(N ** 2)
        3. Nested For-Loops but inner For-Loop starts at i + 1 (instead of 0).
            - The outer For-Loop iterates over N elements
            - The inner For-Loop iterates through N-1, N-2, N-3... N-(N - 1) elements
                - The average of the elements the inner For-Loop iterates through is N/2
                    - Therefore the overall time complexity is O(N ** 2 / 2) == O(N ** 2)
        4. If outer for-loop iterates through A elements and inner for-loop iterates through B elements then time complexity is O(AB) != O(N ** 2)
        5. Drop Constants O(AB * 100000) == O(AB)
        6. Drop Constants O(N / 2) == O(N), ex: reversing an array
        7. Which elements are equivalent to O(N)




    
    